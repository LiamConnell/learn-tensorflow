{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.models.rnn import rnn, rnn_cell\n",
    "import numpy as np\n",
    "import numpy.random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas.io.data as web\n",
    "from pykalman import KalmanFilter\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prices(symbol):\n",
    "    start, end = '2007-05-02', '2016-04-11'\n",
    "    data = web.DataReader(symbol, 'yahoo', start, end)\n",
    "    data=pd.DataFrame(data)\n",
    "    prices=data['Adj Close']\n",
    "    #prices=np.asarray(list(prices))\n",
    "    prices=prices.astype(float)\n",
    "    return prices\n",
    "\n",
    "gs = get_prices('GS')\n",
    "\n",
    "def get_returns(prices):\n",
    "    return (prices-prices.shift(-1))/prices\n",
    "\n",
    "rets = get_returns(gs)\n",
    "\n",
    "def sort_data(rets, N):\n",
    "    ins = []\n",
    "    outs = []\n",
    "    for i in range(N):\n",
    "        xx = np.random.randint(len(rets)-100)\n",
    "        ins.append(rets[xx:xx+100].tolist())\n",
    "        outs.append(rets[xx+100])\n",
    "    return np.array(ins), np.array(outs)\n",
    "\n",
    "ins, outs = sort_data(rets, 1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xdata = np.array(rets[:-1])\n",
    "ydata = np.copy(xdata)\n",
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 1])\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "#training_iters = 1000\n",
    "#batch_size = 128\n",
    "#display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "#n_input = 1 # MNIST data input (img shape: 28*28)\n",
    "#n_steps = 100 # timesteps\n",
    "#n_hidden = 100 # hidden layer num of features\n",
    "#n_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([1, 100])),\n",
    "    'out': tf.Variable(tf.random_normal([100, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([100])),\n",
    "    'out': tf.Variable(tf.random_normal([1]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_hidden)\n",
    "    \n",
    "    # Permuting batch_size and n_steps\n",
    "    #x = tf.transpose(x)\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    #x = tf.reshape(x, [-1, n_input])\n",
    "    \n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "    x = tf.split(0, len(xdata), x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(100, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.l2_loss(pred - y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (2,) for Tensor 'Placeholder:0', which has shape (Dimension(None), Dimension(1))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8e5433c5cd54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#batch_xs, batch_ys = mnist.train.next_batch(100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    362\u001b[0m                   \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m                   % (np_val.shape, subfeed_t.name,\n\u001b[0;32m--> 364\u001b[0;31m                      tuple(subfeed_t.get_shape().dims)))\n\u001b[0m\u001b[1;32m    365\u001b[0m           \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (2,) for Tensor 'Placeholder:0', which has shape (Dimension(None), Dimension(1))"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    #batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(optimizer, feed_dict={x: xdata.reshape(1,-1).T.shape, y_: ydata})\n",
    "    if (epoch+1)%100== 0:\n",
    "        c = sess.run(cost, feed_dict={x: xdata, y_: ydata})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2251, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdata.reshape(1,-1).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_iters = 1000\n",
    "#batch_size = 128\n",
    "#display_step = 10\n",
    "\n",
    "# Network Parameters\n",
    "n_input = 1 # MNIST data input (img shape: 28*28)\n",
    "n_steps = 100 # timesteps\n",
    "n_hidden = 100 # hidden layer num of features\n",
    "n_classes = 1 # MNIST total classes (0-9 digits)\n",
    "\n",
    "# tf Graph input\n",
    "\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_input, n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden, n_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'hidden': tf.Variable(tf.random_normal([n_hidden])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Linear expects shape[1] of arguments: [[1, None], [None, 100]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-140db2d22fdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Define loss and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-140db2d22fdc>\u001b[0m in \u001b[0;36mRNN\u001b[0;34m(x, weights, biases)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# Get lstm cell output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_cell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Linear activation, using rnn inner loop last output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mrnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m    112\u001b[0m             lambda: zero_output_state, output_state)\n\u001b[1;32m    113\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36moutput_state\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;31m# pylint: disable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0moutput_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m       \u001b[0;31m# pylint: enable=cell-var-from-loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/rnn_cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    188\u001b[0m       \u001b[0;31m# Parameters of gates are concatenated into one multiply for efficiency.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m       \u001b[0mconcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m       \u001b[0;31m# i = input_gate, j = new_input, f = forget_gate, o = output_gate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/rnn_cell.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(args, output_size, bias, bias_start, scope)\u001b[0m\n\u001b[1;32m    670\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Linear is expecting 2D arguments: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Linear expects shape[1] of arguments: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m       \u001b[0mtotal_arg_size\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Linear expects shape[1] of arguments: [[1, None], [None, 100]]"
     ]
    }
   ],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, n_steps, n_input)\n",
    "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_hidden)\n",
    "    \n",
    "    # Permuting batch_size and n_steps\n",
    "    x = tf.transpose(x)\n",
    "    # Reshaping to (n_steps*batch_size, n_input)\n",
    "    #x = tf.reshape(x, [-1, n_input])\n",
    "    \n",
    "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_hidden)\n",
    "    x = tf.split(0, n_steps, x)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
    "\n",
    "pred = RNN(x, weights, biases)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.l2_loss(pred - y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [10,1] vs. [1000,1]\n\t [[Node: gradients/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/sub_grad/Shape, gradients/sub_grad/Shape_1)]]\nCaused by op 'gradients/sub_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-c245d93e2574>\", line 28, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 186, in minimize\n    aggregation_method=aggregation_method)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 232, in compute_gradients\n    aggregation_method=aggregation_method)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py\", line 445, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/math_grad.py\", line 278, in _SubGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 30, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'sub', defined at:\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 17 identical lines from previous traceback]\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-c245d93e2574>\", line 27, in <module>\n    cost = tf.reduce_mean(tf.nn.l2_loss(pred - y_))\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1282, in sub\n    return _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStatusNotOK\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    427\u001b[0m       return tf_session.TF_Run(self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 428\u001b[0;31m                                target_list)\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStatusNotOK\u001b[0m: Invalid argument: Incompatible shapes: [10,1] vs. [1000,1]\n\t [[Node: gradients/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/sub_grad/Shape, gradients/sub_grad/Shape_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-320619952484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#batch_xs, batch_ys = mnist.train.next_batch(100)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_fetch_targets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[0;31m# User may have fetched the same tensor multiple times, but we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, target_list, fetch_list, feed_dict)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         raise errors._make_specific_exception(node_def, op, error_message,\n\u001b[0;32m--> 444\u001b[0;31m                                               e.code)\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me_traceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [10,1] vs. [1000,1]\n\t [[Node: gradients/sub_grad/BroadcastGradientArgs = BroadcastGradientArgs[_device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/sub_grad/Shape, gradients/sub_grad/Shape_1)]]\nCaused by op 'gradients/sub_grad/BroadcastGradientArgs', defined at:\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/config/application.py\", line 574, in launch_instance\n    app.start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelapp.py\", line 373, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/ioloop.py\", line 151, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/ioloop.py\", line 866, in start\n    handler_func(fd_obj, events)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 433, in _handle_events\n    self._handle_recv()\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 465, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/zmq/eventloop/zmqstream.py\", line 407, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 252, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 213, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/kernelbase.py\", line 362, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/kernel/zmq/ipkernel.py\", line 181, in do_execute\n    shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2871, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 2975, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-c245d93e2574>\", line 28, in <module>\n    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 186, in minimize\n    aggregation_method=aggregation_method)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/training/optimizer.py\", line 232, in compute_gradients\n    aggregation_method=aggregation_method)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gradients.py\", line 445, in gradients\n    in_grads = _AsList(grad_fn(op_wrapper, *out_grads))\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/math_grad.py\", line 278, in _SubGrad\n    rx, ry = gen_array_ops._broadcast_gradient_args(sx, sy)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 30, in _broadcast_gradient_args\n    name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n\n...which was originally created as op 'sub', defined at:\n  File \"/Users/liamconnell/anaconda/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 17 identical lines from previous traceback]\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/IPython/core/interactiveshell.py\", line 3035, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-c245d93e2574>\", line 27, in <module>\n    cost = tf.reduce_mean(tf.nn.l2_loss(pred - y_))\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/math_ops.py\", line 426, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 1282, in sub\n    return _op_def_lib.apply_op(\"Sub\", x=x, y=y, name=name)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/liamconnell/anaconda/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "\n",
    "for epoch in range(2000):\n",
    "    #batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(optimizer, feed_dict={x: ins, y_: outs.reshape(1,-1).T})\n",
    "    if (epoch+1)%100== 0:\n",
    "        c = sess.run(cost, feed_dict={x: ins, y_: outs.reshape(1,-1).T})\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)\n",
    "step = 1\n",
    "# Keep training until reach max iterations\n",
    "while step * batch_size < training_iters:\n",
    "    #batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "    # Reshape data to get 28 seq of 28 elements\n",
    "    batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
    "    # Run optimization op (backprop)\n",
    "    sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
    "    if step % display_step == 0:\n",
    "        # Calculate batch accuracy\n",
    "        acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
    "        # Calculate batch loss\n",
    "        loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
    "        print \"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
    "              \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "              \"{:.5f}\".format(acc)\n",
    "    step += 1\n",
    "print \"Optimization Finished!\"\n",
    "\n",
    "# Calculate accuracy for 128 mnist test images\n",
    "test_len = 128\n",
    "test_data = mnist.test.images[:test_len].reshape((-1, n_steps, n_input))\n",
    "test_label = mnist.test.labels[:test_len]\n",
    "print \"Testing Accuracy:\", \\\n",
    "    sess.run(accuracy, feed_dict={x: test_data, y: test_label})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
